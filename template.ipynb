{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read All Dataset CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names=[]\n",
    "X_trains=[]\n",
    "y_trains=[]\n",
    "X_tests=[]\n",
    "for folder_name in os.listdir(\"./Competition_data\"):\n",
    "    # print(folder_name)\n",
    "    dataset_names.append(folder_name)\n",
    "    X_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_train.csv\",header=0))\n",
    "    y_trains.append(pd.read_csv(f\"./Competition_data/{folder_name}/y_train.csv\",header=0))\n",
    "    X_tests.append(pd.read_csv(f\"./Competition_data/{folder_name}/X_test.csv\",header=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# 資料前處理與特徵工程\n",
    "# 我們會進行缺失值處理、標準化與編碼\n",
    "X_trains_processed = []\n",
    "X_tests_processed = []\n",
    "\n",
    "for i in range(len(dataset_names)):\n",
    "    # 1. 將 X_train 和 X_test 轉換為 DataFrame 格式\n",
    "    X_train_df = pd.DataFrame(X_trains[i].copy())\n",
    "    X_test_df = pd.DataFrame(X_tests[i].copy()) \n",
    "\n",
    "    # 2. 缺失值處理\n",
    "    imputer = SimpleImputer(strategy=\"mean\")  #用「均值填補」的方式來處理缺失值，即將資料列中的缺失值填充為該列的平均值。\n",
    "    X_train_df = imputer.fit_transform(X_train_df)#這一步會在訓練資料集（X_train_df）中計算出每一列的均值並用其填補缺失值。\n",
    "    X_test_df = imputer.transform(X_test_df)#這一步使用訓練資料集（X_train_df）計算的均值來填補測試資料集（X_test_df）的缺失值。這樣保證測試集的處理與訓練集一致。\n",
    "\n",
    "\n",
    "    X_train_df = pd.DataFrame(X_train_df)  # 轉回 DataFrame 以便進行 select_dtypes\n",
    "    X_test_df = pd.DataFrame(X_test_df)    # 轉回 DataFrame 以便進行 select_dtypes\n",
    "\n",
    "    #目標：將資料中的類別型特徵轉換為數字型資料。原因：許多機器學習模型（如隨機森林、SVM等）只能處理數字資料，因此需要將資料中的類別型特徵（例如文字型的類別）轉換成數字。\n",
    "    for col in X_train_df.select_dtypes(include=['object']).columns:#所有的 object 類型資料（通常為類別型資料）。這裡假設類別型特徵的資料型態是 object，例如 'A', 'B', 'C' 等。\n",
    "        encoder = LabelEncoder()\n",
    "        X_train_df[col] = encoder.fit_transform(X_train_df[col])#對訓練資料（X_train_df）中的每個類別型欄位進行編碼。\n",
    "        X_test_df[col] = encoder.transform(X_test_df[col])#對測試資料（X_test_df）進行編碼，這樣測試資料的編碼會使用與訓練資料相同的映射。\n",
    "\n",
    "    # 4. 標準化數值特徵\n",
    "    scaler = StandardScaler()\n",
    "    X_train_df = scaler.fit_transform(X_train_df)\n",
    "    X_test_df = scaler.transform(X_test_df)\n",
    "\n",
    "    # 將處理過的資料存入 list 中\n",
    "    X_trains_processed.append(X_train_df)\n",
    "    X_tests_processed.append(X_test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split & build Model\n",
    "You can select an appropriate model and perform corresponding hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=[]\n",
    "for i in range(len(dataset_names)):\n",
    "    tmp_X_train, tmp_X_test, tmp_y_train, tmp_y_test = train_test_split(X_trains[i], y_trains[i], test_size=0.2, random_state=42)\n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(tmp_X_train, tmp_y_train.squeeze())\n",
    "    tmp_y_prob = model.predict_proba(tmp_X_test)[:, 1]\n",
    "    auc = roc_auc_score(tmp_y_test, tmp_y_prob)\n",
    "    models.append(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicts=[]\n",
    "for i in range(len(dataset_names)):\n",
    "    y_predict_proba=models[i].predict_proba(X_tests[i])[:, 1]\n",
    "    df = pd.DataFrame(y_predict_proba, columns=['y_predict_proba'])\n",
    "    y_predicts.append(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx,dataset_name in enumerate(dataset_names):\n",
    "    df=y_predicts[idx]\n",
    "    df.to_csv(f'./Competition_data/{dataset_name}/y_predict.csv', index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
